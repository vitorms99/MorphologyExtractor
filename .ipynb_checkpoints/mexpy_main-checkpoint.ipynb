{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76baa778-c754-46b7-a4a3-ce058f08f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.nddata import Cutout2D\n",
    "import warnings\n",
    "import os\n",
    "import re\n",
    "import sep\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from multiprocessing import get_logger\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "from multiprocessing import shared_memory, Pool\n",
    "import multiprocessing\n",
    "from GUI import run_gui\n",
    "from mexpy.Utils_module import get_files_with_format, vary_galaxy_image, remove_central_region, centralize_on_main_obj\n",
    "from mexpy.Background_module import BackgroundEstimator\n",
    "from mexpy.Detection_module import ObjectDetector\n",
    "from mexpy.Cleaning_module import GalaxyCleaner\n",
    "from mexpy.Petrosian_module import PetrosianCalculator\n",
    "from mexpy.Flagging_module import FlaggingHandler\n",
    "from mexpy.Segmentation_module import SegmentImage\n",
    "from mexpy.Metrics_module import Concentration, Asymmetry, Smoothness, Shannon_entropy, Moment_of_light, Gini_index, GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc33310-2d5c-498a-8ff4-e36a8013d873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_galaxy(*args):\n",
    "    galaxy_file, user_inputs, x_i, y_i  = args\n",
    "\n",
    "    # Initialize procedure flag and results dict\n",
    "    result_row = {}\n",
    "    try:\n",
    "        #### Load galaxy\n",
    "        if user_inputs['processing_type'] == 'cutout':\n",
    "            \n",
    "            galaxy_name = os.path.splitext(galaxy_file)[0]\n",
    "            logging.info(f\"Processing {galaxy_name}...\")\n",
    "\n",
    "            result_row['obj'] = galaxy_name\n",
    "            result_row['load_flag'] = 1\n",
    "            image_path = os.path.join(user_inputs['images_folder'], galaxy_file)\n",
    "            galaxy_fits = fits.open(image_path)\n",
    "            header = galaxy_fits[0].header\n",
    "            galaxy_image = galaxy_fits[0].data\n",
    "            galaxy_image = galaxy_image.astype(float)\n",
    "            if galaxy_image.ndim != 2:\n",
    "                raise ValueError(f\"Expected a 2D image, but received {galaxy_image.ndim}D data. Check the input file: {galaxy_name}\")\n",
    "            result_row['load_flag'] = 0\n",
    "            \n",
    "        elif user_inputs['processing_type'] == 'field':\n",
    "            result_row['load_flag'] = 1\n",
    "            existing_field = shared_memory.SharedMemory(name=shared_field.name)\n",
    "            galaxy_name = os.path.splitext(os.path.basename(user_inputs['auxiliary_file']))[0] + '_' + str(i)\n",
    "            logging.info(f\"Processing {galaxy_name}...\")\n",
    "            galaxy_image = Cutout2D(existing_field, (x_i, y_i), user_inputs['initial_cutout_size']).data\n",
    "            result_row['load_flag'] = 0\n",
    "            \n",
    "        xc, yc = int(round(len(galaxy_image[0])/2)), int(round(len(galaxy_image)/2))\n",
    "        \n",
    "        nogalaxy = 0\n",
    "        if galaxy_image[xc, yc] == 0:\n",
    "            nogalaxy = 1\n",
    "            result_row['nogalaxy_flag'] = nogalaxy\n",
    "            logging.info(f\"No galaxy detected at ({x_i}, {y_i}) for {galaxy_name}. Central pixel is zero.\")            \n",
    "            return(result_row)                \n",
    "            \n",
    "        result_row['nogalaxy_flag'] = nogalaxy    \n",
    "        \n",
    "        \n",
    "        ############### BACKGROUND SUBTRACTION ##############################\n",
    "        \n",
    "        if user_inputs['preprocessing_steps']['Subtract Background']:\n",
    "            galaxy_original = np.copy(galaxy_image)\n",
    "            result_row['bkg_flag'] = 1\n",
    "            bkg_estimator = BackgroundEstimator(galaxy_name, galaxy_image)\n",
    "            if user_inputs['bkg_method'] == 'flat':\n",
    "                bkg_median, bkg_std, bkg_image, galaxy_image = bkg_estimator.flat_background(user_inputs['median_mean'], \n",
    "                                                                                             user_inputs['std_dev'])\n",
    "                \n",
    "            elif user_inputs['bkg_method'] == 'frame':\n",
    "                bkg_median, bkg_std, bkg_image, galaxy_image = bkg_estimator.frame_background(user_inputs['image_fraction'], \n",
    "                                                                                              user_inputs['sigma_clip'], \n",
    "                                                                                              user_inputs['clip_threshold'])\n",
    "                \n",
    "            elif user_inputs['bkg_method'] == 'sep':\n",
    "                bkg_median, bkg_std, bkg_image, galaxy_image = bkg_estimator.frame_background(user_inputs['bw'], \n",
    "                                                                                              user_inputs['bh'], \n",
    "                                                                                              user_inputs['fw'],\n",
    "                                                                                              user_inputs['fh'])\n",
    "            \n",
    "            elif user_inputs['bkg_method'] == 'load':\n",
    "                \n",
    "                if user_inputs['processing_type'] == 'field':\n",
    "                    existing_bkg_field = shared_memory.SharedMemory(name=shared_bkg_field.name)\n",
    "            \n",
    "                    bkg_image = Cutout2D(existing_bkg_field, (x0, y0), user_inputs['initial_cutout_size']).data\n",
    "                    bkg_median = np.nanmedian(bkg_image[bkg_image != 0])\n",
    "                    bkg_std = np.nanstd(bkg_image[bkg_image != 0])\n",
    "                    galaxy_image = galaxy_image - bkg_image\n",
    "        \n",
    "                elif user_inputs['processing_type'] == 'cutout':\n",
    "                    bkg_folder = user_inputs['bkg_folder']\n",
    "                    bkg_file = user_inputs['bkg_prefix'] + galaxy_name + user_inputs['bkg_suffix'] + '.fits'\n",
    "                    bkg_path = os.path.join(bkg_folder, bkg_filename)\n",
    "                    bkg_fits = fits.open(bkg_path)\n",
    "                    bkg_image = bkg_fits[user_inputs['bkg_hdu']].data\n",
    "                    bkg_median = np.nanmedian(bkg_image[bkg_image != 0])\n",
    "                    bkg_std = np.nanstd(bkg_image[bkg_image != 0])\n",
    "                    galaxy_image = galaxy_image - bkg_image\n",
    "                    bkg_fits.close()\n",
    "        \n",
    "        \n",
    "            if (user_inputs['save_images']) & (user_inputs['preproc_images']['Background Image']):\n",
    "                if bkg_image is not None:\n",
    "                    hdu = fits.PrimaryHDU(data=bkg_image)\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'Background Image')\n",
    "                    file = os.path.join(folder, galaxy_name + '_bkg.fits')\n",
    "                    hdu.writeto(file, overwrite=True)\n",
    "            result_row['bkg_flag'] = 0\n",
    "            result_row['bkg_median'] = bkg_median\n",
    "            result_row['bkg_std'] = bkg_std\n",
    "        \n",
    "        \n",
    "        ################## OBJECT DETECTION #############################\n",
    "        if user_inputs['preprocessing_steps']['Detect']:\n",
    "            result_row['detect_flag'] = 1\n",
    "            detector = ObjectDetector(galaxy_name, galaxy_image) \n",
    "            if user_inputs['detection_method'] == 'sextractor':\n",
    "                \n",
    "                           \n",
    "                \n",
    "                catalog, first_segmentation = detector.sex_detector(sex_folder = user_inputs['sex_files_folder'], \n",
    "                                                                    sex_default = user_inputs['default_sex_file'], \n",
    "                                                                    sex_keywords = None, \n",
    "                                                                    sex_output_folder = './', \n",
    "                                                                    clean_up = True)\n",
    "        \n",
    "            elif user_inputs['detection_method'] == 'sep':\n",
    "                \n",
    "                if user_inputs['preprocessing_steps']['Subtract Background'] == False:\n",
    "                    sub_bkg = True\n",
    "                    bkg_std = 0\n",
    "                else:\n",
    "                    sub_bkg = False\n",
    "                catalog, first_segmentation = detector.sep_detector(thresh = user_inputs['sep_thresh'], \n",
    "                                                                    minarea = user_inputs['sep_minarea'], \n",
    "                                                                    deblend_nthresh = user_inputs['sep_deblend_nthresh'], \n",
    "                                                                    deblend_cont = user_inputs['sep_deblend_cont'], \n",
    "                                                                    filter_type = user_inputs['sep_filter_type'],\n",
    "                                                                    bkg_std = bkg_std, \n",
    "                                                                    sub_bkg = sub_bkg)\n",
    "        \n",
    "            \n",
    "            xf, yf = len(first_segmentation)//2, len(first_segmentation[0])//2\n",
    "            main_id = first_segmentation[yf,xf]\n",
    "            xm, ym, am, bm, thetam, npixm, magm = catalog.iloc[main_id - 1][['x', 'y', 'a', 'b', 'theta', 'npix', 'mag']]\n",
    "            result_row['x'] = xm\n",
    "            result_row['y'] = ym\n",
    "            result_row['a'] = am\n",
    "            result_row['b'] = bm\n",
    "            result_row['theta'] = thetam\n",
    "            result_row['npix'] = npixm\n",
    "            result_row['mag'] = magm\n",
    "            \n",
    "            folder = os.path.join(user_inputs['output_folder'], 'Detection Catalogs')\n",
    "            file = os.path.join(folder, galaxy_name + '_detection_catalog.csv')\n",
    "            \n",
    "            catalog.to_csv(file, index = False)\n",
    "        \n",
    "            if (user_inputs['save_images']) & (user_inputs['preproc_images']['First Segmentation']):\n",
    "                hdu = fits.PrimaryHDU(data=first_segmentation)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'First Segmentation')\n",
    "                file = os.path.join(folder, galaxy_name + '_first_segm.fits')\n",
    "                hdu.writeto(file, overwrite=True)\n",
    "            \n",
    "            if (user_inputs['save_images']) & (user_inputs['preproc_images']['Objects Detected']):\n",
    "\n",
    "                fig = plt.figure(figsize = (6,6), dpi = 200)\n",
    "    \n",
    "                ax = plt.subplot(111)\n",
    "                m,s = np.mean(galaxy_image), np.std(galaxy_image)\n",
    "                plt.imshow(galaxy_image, cmap = 'gray_r', interpolation='nearest', origin = 'lower', vmin = 0, vmax = m+2*s)\n",
    "                # plot an ellipse for each object\n",
    "                for j in range(len(catalog)):\n",
    "                    e = Ellipse(xy=(catalog['x'][j], catalog['y'][j]),\n",
    "                                width=6*catalog['a'][j],\n",
    "                                height=6*catalog['b'][j],\n",
    "                                angle=catalog['theta'][j] * 180. / np.pi)\n",
    "                    e.set_facecolor('none')\n",
    "                    e.set_edgecolor('red')\n",
    "                    ax.add_artist(e)\n",
    "\n",
    "                plt.plot(xm,ym, 'X', color = 'r')\n",
    "                e = Ellipse(xy=(xm, ym),\n",
    "                                width=6*am,\n",
    "                                height=6*bm,\n",
    "                                angle=(thetam * 180. / np.pi))\n",
    "                e.set_facecolor('none')\n",
    "                e.set_edgecolor('blue')\n",
    "                ax.add_artist(e)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'Objects Detected')\n",
    "                file = os.path.join(folder, galaxy_name + '_Objects_Detected.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "            \n",
    "            result_row['detect_flag'] = 0\n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        ################## CLEAN SECONDARY OBJECTS #############################\n",
    "        if user_inputs['preprocessing_steps']['Cleaning']:\n",
    "            result_row['clean_flag'] = 1\n",
    "            \n",
    "            cleaner = GalaxyCleaner(galaxy_image, first_segmentation)\n",
    "            mean = np.nanmean(galaxy_image[(first_segmentation == 0) & (galaxy_image!=0)])\n",
    "            std = np.nanstd(galaxy_image[(first_segmentation == 0) & (galaxy_image!=0)])\n",
    "            if user_inputs['cleaning_method'] == 'flat':\n",
    "                galaxy_clean = cleaner.flat_filler(median = mean)\n",
    "                \n",
    "            elif user_inputs['cleaning_method'] == 'gaussian':\n",
    "                galaxy_clean = cleaner.gaussian_filler(mean, std)\n",
    "        \n",
    "            elif user_inputs['cleaning_method'] == 'isophotes':\n",
    "                galaxy_clean = cleaner.isophotes_filler(catalog['theta'][main_id - 1])\n",
    "        \n",
    "            if (user_inputs['save_images']) & (user_inputs['preproc_images']['Clean Image']):\n",
    "                hdu = fits.PrimaryHDU(data=galaxy_clean)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'Clean Image')\n",
    "                file = os.path.join(folder, galaxy_name + '_clean.fits')\n",
    "                hdu.writeto(file, overwrite=True)\n",
    "                \n",
    "            result_row['detect_flag'] = 0\n",
    "        \n",
    "        else:\n",
    "            galaxy_clean = galaxy_image.copy()\n",
    "            \n",
    "        ################## LIGHT PROFILE ANALYSIS #############################\n",
    "        if user_inputs['preprocessing_steps']['Light Profile Analysis']:\n",
    "            result_row['petro_flag'] = 1\n",
    "            rp_calc = PetrosianCalculator(galaxy_clean, xm, ym, am, bm, thetam)\n",
    "            eta, growth_curve, radius, rp = rp_calc.calculate_petrosian_radius(rp_thresh = user_inputs['petrosian_eta'], \n",
    "                                                                               aperture = user_inputs['aperture_shape'], \n",
    "                                                                               optimize_rp = user_inputs['optimize_rp'],\n",
    "                                                                               interpolate_order = user_inputs['interp_order'], \n",
    "                                                                               Naround = user_inputs['n_around'], \n",
    "                                                                               rp_step = user_inputs['rp_sampling'])\n",
    "        \n",
    "            result_row['rp_pixels'] = rp\n",
    "            reff, cum_flux, sma_values = rp_calc.calculate_fractional_radius(aperture = user_inputs['aperture_shape'],\n",
    "                                                                             sampling = user_inputs['rp_sampling'])\n",
    "            result_row['reff_pixels'] = reff\n",
    "            \n",
    "            rkron = sep.kron_radius(galaxy_clean, [xm], [ym], [am], [bm], [thetam], r = 10)[0][0]\n",
    "            result_row['rkron_pixels'] = rkron\n",
    "        \n",
    "        \n",
    "            if (user_inputs['save_images']) & (user_inputs['preproc_images']['Light Profile']):\n",
    "                fig = plt.figure(figsize = (12,6), dpi = 200)\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.title('Eta Profile', fontsize = 24)\n",
    "                plt.plot(radius[0:len(eta)], eta, 'bo-', ms = 4)\n",
    "                plt.axvline(rp, color = 'r', ls = '--', label = r'$\\rm r_{P}$')\n",
    "                plt.axhline(0.2, color = 'k', ls = ':')\n",
    "                plt.xlabel('Radius (Pixels)', fontsize = 18)\n",
    "                plt.ylabel(r'$\\rm \\eta(r)$', fontsize = 18)\n",
    "                plt.xticks(fontsize = 16)\n",
    "                plt.yticks(fontsize = 16)\n",
    "                plt.legend(frameon = False, fontsize = 18)\n",
    "                plt.tick_params(direction = 'in', size = 7, left = True, right = True, bottom = True, top = True)\n",
    "        \n",
    "                plt.subplot(1,2,2)\n",
    "                plt.title('Growth Curve', fontsize = 24)\n",
    "                plt.plot(radius[0:len(growth_curve)], growth_curve, 'bo-', ms = 4)\n",
    "                plt.axvline(rp, color = 'r', ls = '--', label = r'$\\rm r_{P}$')\n",
    "                plt.xlabel('Radius (Pixels)', fontsize = 18)\n",
    "                plt.ylabel(r'$\\rm I(r < R)$', fontsize = 18)\n",
    "                plt.xticks(fontsize = 16)\n",
    "                plt.yticks(fontsize = 16)\n",
    "                plt.yscale('log')\n",
    "                plt.legend(frameon = False, fontsize = 18)\n",
    "                plt.tick_params(direction = 'in', size = 7, left = True, right = True, bottom = True, top = True)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'Light Profile')\n",
    "                file = os.path.join(folder, galaxy_name + '_light_profile.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "            result_row['petro_flag'] = 0\n",
    "                    \n",
    "        ################## FLAGGING PROCEDURE #############################        \n",
    "        if user_inputs['preprocessing_steps']['Flagging']:\n",
    "            result_row['flagging_flag'] = 1\n",
    "            flagger = FlaggingHandler(catalog, first_segmentation, galaxy_image)\n",
    "            delta_mag = user_inputs['delta_mag']\n",
    "            k_flag = user_inputs['k_flag']\n",
    "            nsec_max = user_inputs['max_secondary_objects']\n",
    "            if user_inputs['flagging_scale_radius'] == 'Reff':\n",
    "                r_flag = reff\n",
    "            elif user_inputs['flagging_scale_radius'] == 'Rp':\n",
    "                r_flag = rp\n",
    "            \n",
    "            elif user_inputs['flagging_scale_radius'] == 'Rkron':\n",
    "                r_flag = rkron\n",
    "            \n",
    "            flags = flagger.flag_objects(k_flag = k_flag, delta_mag = delta_mag, nsec_max = nsec_max, r = r_flag)\n",
    "            result_row.update(flags)\n",
    "            result_row['flagging_flag'] = 0\n",
    "            \n",
    "        \n",
    "        ################## SEGMENTATION MASK #############################        \n",
    "        if user_inputs['preprocessing_steps']['Segmentation']:\n",
    "            result_row['segmentation_flag'] = 1\n",
    "            if user_inputs['segmentation_scale_radius'] == 'Reff':\n",
    "                rsegm = reff\n",
    "            elif user_inputs['segmentation_scale_radius'] == 'Rp':\n",
    "                rsegm = rp\n",
    "            elif user_inputs['segmentation_scale_radius'] == 'Rkron':\n",
    "                rsegm = rkron\n",
    "        \n",
    "            k_segmentation = user_inputs['scale_factor']\n",
    "            \n",
    "            segm = SegmentImage(galaxy_clean, first_segmentation, rsegm, xm, ym, am, bm, thetam)\n",
    "        \n",
    "            if user_inputs['segmentation_method'] == 'original':\n",
    "                segmentation_mask = segm._get_original()\n",
    "                \n",
    "            elif user_inputs['segmentation_method'] == 'radius':\n",
    "                segmentation_mask = segm._limit_to_ellipse(k_segmentation = k_segmentation)\n",
    "            \n",
    "            elif user_inputs['segmentation_method'] == 'intensity':\n",
    "                segmentation_mask = segm._limit_to_intensity(k_segmentation = k_segmentation)\n",
    "        \n",
    "        else: \n",
    "            segmentation_mask = np.ones(galaxy_clean.shape)\n",
    "        \n",
    "        if (user_inputs['save_images']) & (user_inputs['preproc_images']['Segmentation Mask']):\n",
    "            folder = os.path.join(user_inputs['output_folder'], 'Segmentation Mask')\n",
    "            file = os.path.join(folder, galaxy_name + '_segmentation_mask.jpg')\n",
    "            hdu = fits.PrimaryHDU(data=segmentation_mask)\n",
    "            hdu.writeto(file, overwrite=True)\n",
    "        result_row['segmentation_flag'] = 0\n",
    "    \n",
    "        \n",
    "        if user_inputs['processing_type'] == 'field':\n",
    "            if user_inputs['cutout_scale_radius'] == 'Rp':\n",
    "                new_size = user_inputs['final_cutout_scale'] * rp\n",
    "            elif user_inputs['cutout_scale_radius'] == 'Reff':\n",
    "                new_size = user_inputs['final_cutout_scale'] * reff\n",
    "            elif user_inputs['cutout_scale_radius'] == 'Rkron':\n",
    "                new_size = user_inputs['final_cutout_scale'] * rkron\n",
    "        \n",
    "            if new_size >= user_inputs['initial_cutout_size']:\n",
    "                warnings.warn(f\"Final cutout size is larger than initial cutout for {galaxy_name}...results may not be reliable...\")\n",
    "                \n",
    "            galaxy_clean = Cutout2D(galaxy_clean, (xm, ym), new_size, mode = 'trim').data\n",
    "            segmentation_mask = Cutout2D(segmentation_mask, (xm, ym), new_size, mode = 'trim').data\n",
    "        \n",
    "        elif user_inputs['processing_type'] == 'cutout':\n",
    "            galaxy_clean = centralize_on_main_obj(xm, ym, galaxy_clean, size_method=\"auto\")\n",
    "            segmentation_mask = centralize_on_main_obj(xm, ym, segmentation_mask, size_method=\"input\", size = len(galaxy_clean))\n",
    "        \n",
    "        index = np.where(segmentation_mask == 1)\n",
    "        delta1 = np.max(index[0]) - np.min(index[0])\n",
    "        delta2 = np.max(index[1]) - np.min(index[1])\n",
    "        delta = round(1.5*max(delta1, delta2)/2)\n",
    "        x0, y0 = round(len(segmentation_mask[0])/2), round(len(segmentation_mask)/2)\n",
    "        ymin = (y0 - delta) if (y0-delta) >= 0 else 0\n",
    "        ymax = (y0 + delta + 1) if (y0+delta) <= len(segmentation_mask) else len(segmentation_mask)\n",
    "        xmin = (x0 - delta) if (x0-delta) >= 0 else 0\n",
    "        xmax = (x0 + delta + 1) if (x0+delta) <= len(segmentation_mask[0]) else len(segmentation_mask[0])\n",
    "        \n",
    "        segmented_mini = segmentation_mask[ymin : ymax,\n",
    "                                           xmin : xmax]\n",
    "        \n",
    "        clean_mini = galaxy_clean[ymin : ymax,\n",
    "                                  xmin : xmax]\n",
    "        \n",
    "        \n",
    "        if (user_inputs['measure_indexes']['Smoothness']) | ((user_inputs['measure_indexes']['Asymmetry']) & (user_inputs['A_remove_center'])):\n",
    "            delta1 = ymax - ymin  # Height\n",
    "            delta2 = xmax - xmin  # Width\n",
    "            noise_mini = galaxy_clean[0:delta1, 0:delta2]\n",
    "\n",
    "        else:\n",
    "            noise_mini = None\n",
    "\n",
    "        \n",
    "        if (user_inputs['save_images']) & (user_inputs['useful_images']['Combined FITS']):\n",
    "            x1, y1 = round(len(clean_mini[0])), round(len(clean_mini)) \n",
    "            # Define header values\n",
    "            header_values = {\n",
    "                'X': x1,\n",
    "                'Y': y1,\n",
    "                'A': am,\n",
    "                'B': bm,\n",
    "                'THETA': thetam}\n",
    "            hdu_primary = fits.PrimaryHDU()\n",
    "            image_hdu1 = fits.ImageHDU(data=clean_mini, name='IMAGE1')\n",
    "            image_hdu2 = fits.ImageHDU(data=segmented_mini, name='IMAGE2')\n",
    "            if noise_mini is not None:\n",
    "                image_hdu3 = fits.ImageHDU(data=noise_mini, name='IMAGE3')\n",
    "                # Add header information\n",
    "                for key, value in header_values.items():\n",
    "                    image_hdu1.header[key] = value  # Add to first image\n",
    "                    image_hdu2.header[key] = value  # Add to second image\n",
    "                    image_hdu3.header[key] = value  # Add to second image\n",
    "                hdul = fits.HDUList([hdu_primary, image_hdu1, image_hdu2, image_hdu3])\n",
    "            else:\n",
    "                # Add header information\n",
    "                for key, value in header_values.items():\n",
    "                    image_hdu1.header[key] = value  # Add to first image\n",
    "                    image_hdu2.header[key] = value  # Add to second image\n",
    "                hdul = fits.HDUList([hdu_primary, image_hdu1, image_hdu2])\n",
    "               \n",
    "            folder = os.path.join(user_inputs['output_folder'], 'Combined FITS')\n",
    "            file = os.path.join(folder, galaxy_name + '_Combined_FITS.fits')\n",
    "            hdul.writeto(file, overwrite=True)    \n",
    "        \n",
    "            \n",
    "        ######### MEASURE METRICS\n",
    "        if user_inputs['measure_indexes']['Concentration']:\n",
    "            result_row['C_flag'] = 1\n",
    "        \n",
    "            if user_inputs['C_scale_radius'] == 'Rp':\n",
    "                rs_c = rp\n",
    "            elif user_inputs['C_scale_radius'] == 'Reff':\n",
    "                rs_c = reff\n",
    "            elif user_inputs['C_scale_radius'] == 'Rkron':\n",
    "                rs_c = rkron\n",
    "        \n",
    "            conc = Concentration(galaxy_clean.copy())\n",
    "            if (user_inputs['save_images']) & (user_inputs['output_metrics']['C Curve']):\n",
    "                fig = conc.plot_growth_curve(xm, ym, am, bm, thetam, rmax=user_inputs['k_max'] * rs_c, \n",
    "                                             sampling_step=0.5, f_inner = user_inputs['inner_fraction'], \n",
    "                                             f_outter= user_inputs['outer_fraction'], Naround=3, interp_order=3)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'C Curve')\n",
    "                file = os.path.join(folder, galaxy_name + '_C_Curve.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "                \n",
    "            ###### Conselice\n",
    "            if user_inputs['C_conselice']:\n",
    "                ###### Measure at given position\n",
    "                Cc0, rinner0, routter0 = conc.get_concentration(x = xm, \n",
    "                                                            y = ym, \n",
    "                                                            a = am, \n",
    "                                                            b = bm, \n",
    "                                                            theta = thetam,\n",
    "                                                            method = 'conselice', \n",
    "                                                            f_inner = user_inputs['inner_fraction'], \n",
    "                                                            f_outter = user_inputs['outer_fraction'],\n",
    "                                                            rmax = user_inputs['k_max'] * rs_c, \n",
    "                                                            sampling_step = 0.5, \n",
    "                                                            Naround = 3, \n",
    "                                                            interp_order = 3)\n",
    "        \n",
    "                result_row['C_c'] = Cc0\n",
    "                result_row['Rinner'] = rinner0\n",
    "                result_row['Routter'] = routter0\n",
    "                \n",
    "                    \n",
    "        \n",
    "        \n",
    "        \n",
    "            ###### Barchi\n",
    "            if user_inputs['C_barchi']:\n",
    "                ###### Measure at given position\n",
    "                Cb0, rinner0, routter0 = conc.get_concentration(x = xm, \n",
    "                                                            y = ym, \n",
    "                                                            a = am, \n",
    "                                                            b = bm, \n",
    "                                                            theta = thetam,\n",
    "                                                            method = 'barchi', \n",
    "                                                            f_inner = user_inputs['inner_fraction'], \n",
    "                                                            f_outter = user_inputs['outer_fraction'],\n",
    "                                                            rmax = user_inputs['k_max'] * rs_c, \n",
    "                                                            sampling_step = 0.05, \n",
    "                                                            Naround = 3, \n",
    "                                                            interp_order = 3)\n",
    "        \n",
    "                result_row['C_b'] = Cb0\n",
    "                result_row['Rinner'] = rinner0\n",
    "                result_row['Routter'] = routter0\n",
    "        \n",
    "                \n",
    "        \n",
    "        \n",
    "            result_row['C_flag'] = 0\n",
    "        \n",
    "        if user_inputs['measure_indexes']['Asymmetry']:\n",
    "            result_row['A_flag'] = 1\n",
    "            if user_inputs['A_remove_center']:\n",
    "                if user_inputs['A_remove_scale_radius'] == 'Rp':\n",
    "                    rs_a = rp\n",
    "                elif user_inputs['A_remove_scale_radius'] == 'Reff':\n",
    "                    rs_a = reff\n",
    "                elif user_inputs['A_remove_scale_radius'] == 'Rkron':\n",
    "                    rs_a = rkron\n",
    "                xc,yc = round(len(clean_mini[0])/2), round(len(clean_mini)/2)\n",
    "                new_segmentation = remove_central_region(segmented_mini, \n",
    "                                                         remove_radius = user_inputs['A_percentage_removal']*rs_a/100, \n",
    "                                                         xc = xc, \n",
    "                                                         yc = yc)\n",
    "            else:\n",
    "                new_segmentation = segmented_mini.copy()\n",
    "        \n",
    "            asy = Asymmetry(clean_mini, \n",
    "                            angle = user_inputs['A_rotation_angle'], \n",
    "                            segmentation = new_segmentation, \n",
    "                            noise = noise_mini if user_inputs['A_noise_estimate'] else None)\n",
    "\n",
    "            if (user_inputs['save_images']):\n",
    "                if (user_inputs['output_metrics']['A Comparison']):\n",
    "                    fig = asy.plot_asymmetry_comparison()\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'A Comparison')\n",
    "                    file = os.path.join(folder, galaxy_name + '_A_Comparison.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "                if (user_inputs['output_metrics']['A Scatter']):\n",
    "                    fig = asy.plot_asymmetry_scatter()\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'A Scatter')\n",
    "                    file = os.path.join(folder, galaxy_name + '_A_Scatter.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "            \n",
    "            if user_inputs['A_conselice']:        \n",
    "                A_final, A_galaxy, A_noise = asy.conselice_asymmetry(comparison = user_inputs['A_pixel_comparison'])\n",
    "                result_row['A_c_f'] = A_final\n",
    "                result_row['A_c_g'] = A_galaxy\n",
    "                result_row['A_c_n'] = A_noise\n",
    "                \n",
    "            if user_inputs['A_barchi']:\n",
    "                _, A_galaxy, _ = asy.barchi_asymmetry(comparison = user_inputs['A_pixel_comparison'])\n",
    "                result_row['A_b'] = A_galaxy\n",
    "                \n",
    "            if user_inputs['A_sampaio']:        \n",
    "                A_final, A_galaxy, A_noise = asy.sampaio_asymmetry(comparison = user_inputs['A_pixel_comparison'])\n",
    "                result_row['A_s_f'] = A_final\n",
    "                result_row['A_s_g'] = A_galaxy\n",
    "                result_row['A_s_n'] = A_noise\n",
    "        \n",
    "            result_row['A_flag'] = 0\n",
    "        \n",
    "            \n",
    "        \n",
    "        if user_inputs['measure_indexes']['Smoothness']:\n",
    "            result_row['S_flag'] = 1\n",
    "            if user_inputs['S_remove_center']:\n",
    "                if user_inputs['S_remove_scale_radius'] == 'Rp':\n",
    "                    rs_s = rp\n",
    "                elif user_inputs['S_remove_scale_radius'] == 'Reff':\n",
    "                    rs_s = reff\n",
    "                elif user_inputs['S_remove_scale_radius'] == 'Rkron':\n",
    "                    rs_s = rkron\n",
    "                xc,yc = round(len(clean_mini[0])/2), round(len(clean_mini)/2)\n",
    "                new_segmentation = remove_central_region(segmented_mini, \n",
    "                                                         remove_radius = user_inputs['S_percentage_removal']*rs_s/100, \n",
    "                                                         xc = xc, \n",
    "                                                         yc = yc)\n",
    "            else:\n",
    "                new_segmentation = segmented_mini.copy()\n",
    "\n",
    "            smo = Smoothness(clean_mini, \n",
    "                             segmentation = new_segmentation, \n",
    "                             noise = noise_mini, \n",
    "                             smoothing_factor = rs_s/user_inputs['S_smooth_factor'], \n",
    "                             smoothing_filter = user_inputs['S_smoothing_filter'])\n",
    "            \n",
    "            if (user_inputs['save_images']):\n",
    "                if (user_inputs['output_metrics'][\"S Comparison\"]):\n",
    "                    fig = smo.plot_smoothness_comparison()\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'S Comparison')\n",
    "                    file = os.path.join(folder, galaxy_name + '_S_Comparison.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "                    \n",
    "                if (user_inputs['output_metrics'][\"S Scatter\"]):\n",
    "                    fig = smo.plot_smoothness_scatter()\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'S Scatter')\n",
    "                    file = os.path.join(folder, galaxy_name + '_S_Scatter.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "\n",
    "            \n",
    "        \n",
    "            if user_inputs['S_conselice']:\n",
    "                S_final, _, _ = smo.conselice_smoothness()\n",
    "                result_row['S_c'] = S_final\n",
    "                \n",
    "            if user_inputs['S_barchi']:\n",
    "                _, S_galaxy, _ = smo.barchi_smoothness()\n",
    "                result_row['S_b'] = S_galaxy\n",
    "                \n",
    "            if user_inputs['S_sampaio']:\n",
    "                S_final, S_galaxy, S_noise = smo.sampaio_smoothness()\n",
    "                result_row['S_s_f'] = S_final\n",
    "                result_row['S_s_g'] = S_galaxy\n",
    "                result_row['S_s_n'] = S_noise\n",
    "        \n",
    "        \n",
    "        if user_inputs['measure_indexes']['Shannon Entropy']:\n",
    "            result_row['E_flag'] = 1\n",
    "            if user_inputs['remove_entropy_center']:\n",
    "                if user_inputs['remove_entropy_scale'] == 'Rp':\n",
    "                    rs_h = rp\n",
    "                elif user_inputs['remove_entropy_scale'] == 'Reff':\n",
    "                    rs_h = reff\n",
    "                elif user_inputs['remove_entropy_scale'] == 'Rkron':\n",
    "                    rs_h = rkron\n",
    "                xc,yc = round(len(clean_mini[0])/2), round(len(clean_mini)/2)\n",
    "                new_segmentation = remove_central_region(segmented_mini, \n",
    "                                                         remove_radius = user_inputs['remove_entropy_percentage']*rs_h/100, \n",
    "                                                         xc = xc, \n",
    "                                                         yc = yc)\n",
    "            else:\n",
    "                new_segmentation = segmented_mini.copy()\n",
    "        \n",
    "            entropy_calculator = Shannon_entropy(clean_mini, segmentation=new_segmentation)\n",
    "            if user_inputs['bins_method'] == 'auto':\n",
    "                line = clean_mini[segmented_mini!=0].flatten()\n",
    "                q1 = np.nanquantile(line, .25)\n",
    "                q3 = np.nanquantile(line, .75)\n",
    "                IQR = q3 - q1\n",
    "                h = 2*IQR/(len(line)**(1/3))\n",
    "                # Compute the range of the data\n",
    "                data_range = np.nanmax(line) - np.nanmin(line)\n",
    "                # Compute the number of bins\n",
    "                nbins = int(np.ceil(data_range / h))\n",
    "        \n",
    "            elif user_inputs['bins_method'] == 'fixed':\n",
    "                nbins = user_inputs['n_bins']\n",
    "\n",
    "\n",
    "            if (user_inputs['save_images']) & (user_inputs[\"output_metrics\"][\"E Hist\"]):\n",
    "                fig = entropy_calculator.plot_entropy_frame(bins=\"fixed\", nbins = nbins)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'E Hist')\n",
    "                file = os.path.join(folder, galaxy_name + '_E_Hist.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "            entropy = entropy_calculator.get_entropy(normalize=user_inputs['normalize_hist'], nbins=nbins)\n",
    "            result_row['E'] = entropy\n",
    "            result_row['E_flag'] = 0\n",
    "        \n",
    "        if user_inputs['measure_indexes']['Moment of Light (M20)']:\n",
    "            result_row['M20_flag'] = 1\n",
    "            moment_calculator = Moment_of_light(clean_mini, segmentation=segmented_mini)\n",
    "            x0, y0 = round(len(clean_mini[0])/2), round(len(clean_mini)/2) # assume that central image pixel is center coordinates            \n",
    "            m20 = moment_calculator.get_m20(x0=x0, y0=y0, f=user_inputs['light_fraction'])\n",
    "            if (user_inputs['save_images']) & (user_inputs['output_metrics']['M20 Contributors']):\n",
    "                fig = moment_calculator.plot_M20_contributors(xc, yc, image_cmap = 'Blues')\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'M20 Contributors')\n",
    "                file = os.path.join(folder, galaxy_name + '_M20_Contributors.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "            result_row['M20'] = m20\n",
    "            result_row['M20_flag'] = 0\n",
    "            \n",
    "        if user_inputs['measure_indexes']['Gini Index']:\n",
    "            result_row['Gini_flag'] = 1\n",
    "            gini_calculator = Gini_index(clean_mini, segmentation=segmented_mini)\n",
    "            if (user_inputs['save_images']) & (user_inputs['output_metrics']['Gini Area']):\n",
    "                \n",
    "                gini = gini_calculator.get_gini()\n",
    "                cumulative_pixels, cumulative_light = gini_calculator.compute_lorentz_curve()\n",
    "                fig = gini_calculator.plot_gini_rep(cumulative_pixels, cumulative_light, gini)\n",
    "                folder = os.path.join(user_inputs['output_folder'], 'Gini Area')\n",
    "                file = os.path.join(folder, galaxy_name + '_Gini_Area.jpg')\n",
    "                plt.savefig(file, bbox_inches = 'tight')\n",
    "                plt.close(fig)\n",
    "\n",
    "            \n",
    "            gini = gini_calculator.get_gini()\n",
    "            result_row['Gini'] = gini\n",
    "            result_row['Gini_flag'] = 0\n",
    "        \n",
    "        if user_inputs['measure_indexes']['Gradient Pattern Asymmetry']:\n",
    "            result_row['G2_flag'] = 1\n",
    "            gpa = GPA(image=clean_mini, segmentation=segmented_mini)\n",
    "            if (user_inputs['save_images']):\n",
    "                if (user_inputs['output_metrics']['G2 Field']):\n",
    "                    fig = gpa.plot_gradient_field(mtol=user_inputs['module_tolerance'], \n",
    "                                                  ptol=user_inputs['phase_tolerance'])\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'G2 Field')\n",
    "                    file = os.path.join(folder, galaxy_name + '_G2_Field.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "\n",
    "                if (user_inputs['output_metrics']['G2 Hist']):\n",
    "                    fig = gpa.plot_hists()\n",
    "                    folder = os.path.join(user_inputs['output_folder'], 'G2 Hist')\n",
    "                    file = os.path.join(folder, galaxy_name + '_G2_His.jpg')\n",
    "                    plt.savefig(file, bbox_inches = 'tight')\n",
    "                    plt.close(fig)\n",
    "\n",
    "            g2 = gpa.get_new_g2(mtol=user_inputs['module_tolerance'], \n",
    "                                ptol=user_inputs['phase_tolerance'])\n",
    "            result_row['G2'] = g2\n",
    "            result_row['G2_flag'] = 0\n",
    "        logging.info(f\"Finished processing {galaxy_name}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {galaxy_name}: {e}\")\n",
    "    \n",
    "    return(result_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82b4cfc1-6729-4c17-bad6-97810fd659ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_galaxy_wrapper(args):\n",
    "    return process_galaxy(*args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89948d7e-1d0d-4b11-a979-9e586cc014df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MEx code...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting MEx code...\")\n",
    "current_directory = os.getcwd()\n",
    "max_cores = multiprocessing.cpu_count()\n",
    "bkg_popup_shown = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8306871-4a2f-4c75-baad-8ff5e031f943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration saved...\n"
     ]
    }
   ],
   "source": [
    "user_inputs = run_gui()\n",
    "print(\"Configuration saved...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca8c2d0-e656-4e73-bcc5-4029a74ff708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting configuration sanity checks...\n",
      "Preparing to process 100 fits images found in /home/vitorms/Dropbox/MorphologyExtractor/Examples/test_galaxies using 18 cores...\n",
      "Final configuration is saved in /home/vitorms/Dropbox/test/test_results.json...\n",
      "Step by step progress can be checked in /home/vitorms/Dropbox/test/test_results.log...\n",
      "Final output catalog file will be saved as /home/vitorms/Dropbox/test/test_results.csv...\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting configuration sanity checks...\")\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "################## Pre-processing sanity checks ###################################\n",
    "###################################################################################\n",
    "\n",
    "if user_inputs['preprocessing_steps']['Subtract Background']:\n",
    "    ##### Flat checks\n",
    "    if user_inputs['bkg_method'] == 'flat':\n",
    "    \n",
    "        try:\n",
    "            num = float(user_inputs['median_mean'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid median/mean format in flat background subtraction: {user_inputs['median_mean']}. Proceeding with a default value (0.0)...\", UserWarning)\n",
    "            user_inputs['median_mean'] = 0.0\n",
    "        try:\n",
    "            num = float(user_inputs['std_dev'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid median/mean format in flat background subtraction: {user_inputs['std_dev']}. Proceeding with a default value (1.0)...\", UserWarning)\n",
    "            user_inputs['std_dev'] = 0.0\n",
    "    \n",
    "        if user_inputs['std_dev'] <= 0:\n",
    "          warnings.warn(f\"Inconsistent standard deviation in flat background subtraction. Assuming a nominal value of 1 to continue...\", UserWarning)\n",
    "          user_inputs['std_dev'] = 1\n",
    "    \n",
    "    ### Frame checks\n",
    "    elif user_inputs['bkg_method'] == 'frame':\n",
    "    \n",
    "        try:\n",
    "            num = float(user_inputs['image_fraction'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid image fraction format in frame background subtraction: {user_inputs['image_fraction']}. Proceeding with a default value (0.1)...\", UserWarning)\n",
    "            user_inputs['image_fraction'] = 0.1\n",
    "        try:\n",
    "            num = float(user_inputs['clip_threshold'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid clipping threshold format in frame background subtraction: {user_inputs['clip_threshold']}. Proceeding with a default value (3)...\", UserWarning)\n",
    "            user_inputs['clip_threshold'] = 3\n",
    "            \n",
    "        if (user_inputs['image_fraction'] <= 0) | (user_inputs['image_fraction'] >= 1):\n",
    "          warnings.warn(f\"Inconsistent image fraction parameter in frame background subtraction. Assuming a nominal value of 0.1 to continue...\", UserWarning)\n",
    "          user_inputs['image_fraction'] = 0.1\n",
    "        \n",
    "        if (user_inputs['clip_threshold'] <= 0) & (user_inputs['sigma_clip'] == True):\n",
    "          warnings.warn(f\"Inconsistent clipping threshold in frame background subtraction. Assuming a nominal value of 3 to continue...\", UserWarning)\n",
    "          user_inputs['clip_threshold'] = 3\n",
    "    \n",
    "    ### sep checks\n",
    "    elif user_inputs['bkg_method'] == 'sep':\n",
    "        try:\n",
    "            num = float(user_inputs['bw'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid bw format in sep background subtraction: {user_inputs['bw']}. Proceeding with a default value (32)...\", UserWarning)\n",
    "            user_inputs['bw'] = 32\n",
    "    \n",
    "        try:\n",
    "            num = float(user_inputs['bh'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid bh format in sep background subtraction: {user_inputs['bh']}. Proceeding with a default value (32)...\", UserWarning)\n",
    "            user_inputs['bh'] = 32\n",
    "        \n",
    "        try:\n",
    "            num = float(user_inputs['fw'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid fw format in sep background subtraction: {user_inputs['fw']}. Proceeding with a default value (3)...\", UserWarning)\n",
    "            user_inputs['fw'] = 3\n",
    "        \n",
    "        try:\n",
    "            num = float(user_inputs['fh'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid fh format in sep background subtraction: {user_inputs['fh']}. Proceeding with a default value (3)...\", UserWarning)\n",
    "            user_inputs['fh'] = 3\n",
    "    \n",
    "        if user_inputs['bw'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent bw in sep background subtraction. Assuming a nominal value of 32 to continue...\", UserWarning)\n",
    "            user_inputs['bw'] = 32\n",
    "    \n",
    "        if user_inputs['bh'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent bh in sep background subtraction. Assuming a nominal value of 32 to continue...\", UserWarning)\n",
    "            user_inputs['bh'] = 32\n",
    "    \n",
    "        if user_inputs['fw'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent fw in sep background subtraction. Assuming a nominal value of 3 to continue...\", UserWarning)\n",
    "            user_inputs['fw'] = 3\n",
    "    \n",
    "        if user_inputs['fh'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent fh in sep background subtraction. Assuming a nominal value of 3 to continue...\", UserWarning)\n",
    "            user_inputs['fh'] = 3\n",
    "\n",
    "\n",
    "if user_inputs['preprocessing_steps']['Detect']:\n",
    "\n",
    "    if user_inputs['detection_method'] == 'sep':\n",
    "        try:\n",
    "            num = float(user_inputs['sep_thresh'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Threshold format in sep detection: {user_inputs['sep_thresh']}. Proceeding with a default value (1.5)...\", UserWarning)\n",
    "            user_inputs['sep_thresh'] = 1.5\n",
    "\n",
    "        if user_inputs['sep_thresh'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent threshold in sep detection: {user_inputs['sep_thresh']}. Assuming a nominal value of 1.5 to continue...\", UserWarning)\n",
    "            user_inputs['sep_thresh'] = 1.5            \n",
    "            \n",
    "        try:\n",
    "            num = float(user_inputs['sep_minarea'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Min Area format in sep detection: {user_inputs['sep_minarea']}. Proceeding with a default value (10)...\", UserWarning)\n",
    "            user_inputs['sep_minarea'] = 10\n",
    "\n",
    "        if user_inputs['sep_minarea'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent minarea in sep detection: {user_inputs['sep_minarea']}. Assuming a default value (10) to continue...\", UserWarning)\n",
    "            user_inputs['sep_thresh'] = 1.5            \n",
    "        \n",
    "        try:\n",
    "            num = float(user_inputs['sep_deblend_nthresh'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Deblend N Threshold format in sep detection: {user_inputs['sep_deblend_nthresh']}. Proceeding with a default value (32)...\", UserWarning)\n",
    "            user_inputs['sep_deblend_nthresh'] = 32\n",
    "\n",
    "        if user_inputs['sep_deblend_nthresh'] <= 0:\n",
    "            warnings.warn(f\"Inconsistent deblend_nthresh in sep detection: {user_inputs['sep_deblend_nthresh']}. Assuming a default value (32) to continue...\", UserWarning)\n",
    "            user_inputs['sep_deblend_nthresh'] = 32            \n",
    "\n",
    "\n",
    "        try:\n",
    "            num = float(user_inputs['sep_deblend_cont'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Deblend Cont format in sep detection: {user_inputs['sep_deblend_cont']}. Proceeding with a default value (0.005)...\", UserWarning)\n",
    "            user_inputs['sep_deblend_cont'] = 0.005\n",
    "\n",
    "        if (user_inputs['sep_deblend_cont'] <= 0) | (user_inputs['sep_deblend_cont'] > 1.):\n",
    "            warnings.warn(f\"Inconsistent deblend_cont in sep detection: {user_inputs['sep_deblend_cont']}. Assuming a default value (0.005) to continue...\", UserWarning)\n",
    "            user_inputs['sep_deblend_cont'] = 0.005            \n",
    "        \n",
    "        try:\n",
    "            num = float(user_inputs['sep_gain'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Gain format in sep detection: {user_inputs['sep_gain']}. Proceeding with a default value (1.0)...\", UserWarning)\n",
    "            user_inputs['sep_gain'] = 1.0\n",
    "\n",
    "    if user_inputs['detection_method'] == 'sextractor':\n",
    "        if not os.path.isdir(user_inputs['sex_files_folder']):\n",
    "            raise FileNotFoundError(f\"Folder '{user_inputs['sex_files_folder']}' does not exist.\")\n",
    "        \n",
    "        file_sex = os.path.join(user_inputs['sex_files_folder'], user_inputs['default_sex_file'])\n",
    "\n",
    "        if not os.path.isfile(file_sex):\n",
    "            raise FileNotFoundError(f\"File '{file_sex}' does not exist.\")\n",
    "\n",
    "###################################################################################\n",
    "################## Overall measurements sanity checks #############################\n",
    "###################################################################################\n",
    "\n",
    "###### Flagging parameters checks ###############\n",
    "if user_inputs['preprocessing_steps']['Flagging']:\n",
    "    try:\n",
    "        num = float(user_inputs['k_flag'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid k_flag format in flagging procedure: {user_inputs['k_flag']}. Proceeding with a default value (1.5)...\", UserWarning)\n",
    "        user_inputs['k_flag'] = 1.5\n",
    "        \n",
    "    if (user_inputs['k_flag'] <= 0):\n",
    "        warnings.warn(f\"Inconsistent k_flag in flagging procedure: {user_inputs['k_flag']}. Assuming a default value (1.5) to continue...\", UserWarning)\n",
    "        user_inputs['k_flag'] = 1.5            \n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['delta_mag'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid delta Mag format in flagging procedure: {user_inputs['delta_mag']}. Proceeding with a default value (1)...\", UserWarning)\n",
    "        user_inputs['delta_mag'] = 1\n",
    "        \n",
    "    if (user_inputs['delta_mag'] <= 0):\n",
    "        warnings.warn(f\"Inconsistent delta Mag value in flagging procedure: {user_inputs['delta_mag']}. Assuming a default value (1) to continue...\", UserWarning)\n",
    "        user_inputs['delta_mag'] = 1            \n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['max_secondary_objects'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid Max Secondary Objects format in flagging procedure: {user_inputs['max_secondary_objects']}. Proceeding with a default value (4)...\", UserWarning)\n",
    "        user_inputs['max_secondary_objects'] = 4\n",
    "\n",
    "    if user_inputs['max_secondary_objects'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent Max Secondary Objects value in flagging procedure: {user_inputs['max_secondary_objects']}. Assuming a default value (4) to continue...\", UserWarning)\n",
    "        user_inputs['max_secondary_objects'] = 4            \n",
    "        \n",
    "    \n",
    "###### Light Profile Analysis parameters checks ###############\n",
    "if user_inputs['preprocessing_steps']['Light Profile Analysis']:\n",
    "    try:\n",
    "        num = float(user_inputs['petrosian_eta'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid Eta format in light profile analysis: {user_inputs['petrosian_eta']}. Proceeding with a default value (0.2)...\", UserWarning)\n",
    "        user_inputs['petrosian_eta'] = 0.2\n",
    "\n",
    "    if user_inputs['petrosian_eta'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent petrosian radius Eta value in light profile analysis procedure: {user_inputs['petrosian_eta']}. Assuming a default value (0.2) to continue...\", UserWarning)\n",
    "        user_inputs['petrosian_eta'] = 0.2            \n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['rp_sampling'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid Rp sampling in light profile analysis: {user_inputs['rp_sampling']}. Proceeding with a default value (0.05)...\", UserWarning)\n",
    "        user_inputs['rp_sampling'] = 0.05\n",
    "\n",
    "    if user_inputs['rp_sampling'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent Rp sampling value in light profile analysis procedure: {user_inputs['rp_sampling']}. Assuming a default value (0.05) to continue...\", UserWarning)\n",
    "        user_inputs['rp_sampling'] = 0.05            \n",
    "\n",
    "    try:\n",
    "        num = float(user_inputs['n_around'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid N around in light profile analysis: {user_inputs['n_around']}. Proceeding with a default value (3)...\", UserWarning)\n",
    "        user_inputs['n_around'] = 3\n",
    "\n",
    "    if user_inputs['n_around'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent N around value in light profile analysis procedure: {user_inputs['n_around']}. Assuming a default value (3) to continue...\", UserWarning)\n",
    "        user_inputs['n_around'] = 3            \n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['interp_order'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid interpolation order in light profile analysis: {user_inputs['interp_order']}. Proceeding with a default value (3)...\", UserWarning)\n",
    "        user_inputs['interp_order'] = 3\n",
    "\n",
    "    if user_inputs['interp_order'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent interpolation order value in light profile analysis procedure: {user_inputs['interp_order']}. Assuming a default value (3) to continue...\", UserWarning)\n",
    "        user_inputs['interp_order'] = 3            \n",
    "\n",
    "\n",
    "###### Segmentation parameters checks ###############\n",
    "    try:\n",
    "        num = float(user_inputs['scale_factor'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid scale factor in segmentation process: {user_inputs['scale_factor']}. Proceeding with a default value (1.5)...\", UserWarning)\n",
    "        user_inputs['scale_factor'] = 1.5\n",
    "\n",
    "    if user_inputs['scale_factor'] <= 0:\n",
    "        warnings.warn(f\"Inconsistent scale factor value in segmentation procedure: {user_inputs['scale_factor']}. Assuming a default value (1.5) to continue...\", UserWarning)\n",
    "        user_inputs['scale_factor'] = 1.5\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "############################ CAS sanity checks ####################################\n",
    "###################################################################################\n",
    "if user_inputs['measure_indexes']['Concentration']:\n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['inner_fraction'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid inner fraction in Concentration calculation: {user_inputs['inner_fraction']}. Proceeding with a default value (0.2)...\", UserWarning)\n",
    "        user_inputs['inner_fraction'] = 0.2\n",
    "\n",
    "    if (user_inputs['inner_fraction'] <= 0) | (user_inputs['inner_fraction'] >= user_inputs['outer_fraction']) | (user_inputs['inner_fraction'] >= 1):\n",
    "        warnings.warn(f\"Inconsistent inner fraction value in Concentration calculation: {user_inputs['inner_fraction']}. Assuming a default value (0.2) to continue...\", UserWarning)\n",
    "        user_inputs['inner_fraction'] = 0.2            \n",
    "\n",
    "    try:\n",
    "        num = float(user_inputs['outer_fraction'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid outer fraction in Concentration calculation: {user_inputs['outer_fraction']}. Proceeding with a default value (0.8)...\", UserWarning)\n",
    "        user_inputs['outer_fraction'] = 0.8\n",
    "\n",
    "    if (user_inputs['outer_fraction'] <= 0) | (user_inputs['outer_fraction'] <= user_inputs['inner_fraction']) | (user_inputs['inner_fraction'] >= 1):\n",
    "        warnings.warn(f\"Inconsistent outer fraction value in Concentration calculation: {user_inputs['outer_fraction']}. Assuming a default value (0.2) to continue...\", UserWarning)\n",
    "        user_inputs['outer_fraction'] = 0.8            \n",
    "\n",
    "    try:\n",
    "        num = float(user_inputs['k_max'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid Kmax in Concentration calculation: {user_inputs['k_max']}. Proceeding with a default value (2)...\", UserWarning)\n",
    "        user_inputs['k_max'] = 2\n",
    "\n",
    "    if (user_inputs['k_max'] <= 0) :\n",
    "        warnings.warn(f\"Inconsistent Kmax value in Concentration calculation: {user_inputs['k_max']}. Assuming a default value (2) to continue...\", UserWarning)\n",
    "        user_inputs['outer_fraction'] = 2            \n",
    "\n",
    "\n",
    "if user_inputs['measure_indexes']['Asymmetry']:\n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['A_rotation_angle'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid rotation angle in Asymmetry calculation: {user_inputs['A_rotation_angle']}. Proceeding with a default value (180 deg.)...\", UserWarning)\n",
    "        user_inputs['A_rotation_angle'] = 180\n",
    "\n",
    "    if (user_inputs['A_rotation_angle'] <= 0) | (user_inputs['A_rotation_angle'] >= 360):\n",
    "        warnings.warn(f\"Inconsistent rotation angle value in Asymmetry calculation: {user_inputs['A_rotation_angle']}. Assuming a default value (180 deg.) to continue...\", UserWarning)\n",
    "        user_inputs['A_rotation_angle'] = 180            \n",
    "\n",
    "    if user_inputs['A_remove_center']:\n",
    "        try:\n",
    "            num = float(user_inputs['A_percentage_removal'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid central percentage removal in Asymmetry calculation: {user_inputs['A_percentage_removal']}. Proceeding with a default value (5%)...\", UserWarning)\n",
    "            user_inputs['A_percentage_removal'] = 5.0\n",
    "    \n",
    "        if (user_inputs['A_percentage_removal'] <= 0) | (user_inputs['A_percentage_removal'] >= 100):\n",
    "            warnings.warn(f\"Inconsistent central percentage removal value in Asymmetry calculation: {user_inputs['A_percentage_removal']}. Assuming a default value (5%) to continue...\", UserWarning)\n",
    "            user_inputs['A_percentage_removal'] = 5.0            \n",
    "\n",
    "if user_inputs['measure_indexes']['Smoothness']:\n",
    "    try:\n",
    "        num = float(user_inputs['S_smooth_factor'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid smoothing factor in Smoothness calculation: {user_inputs['S_smooth_factor']}. Proceeding with a default value (5)...\", UserWarning)\n",
    "        user_inputs['S_smooth_factor'] = 5\n",
    "\n",
    "    if (user_inputs['S_smooth_factor'] <= 0):\n",
    "        warnings.warn(f\"Inconsistent smoothing factor value in Smoothness calculation: {user_inputs['S_smooth_factor']}. Assuming a default value (5) to continue...\", UserWarning)\n",
    "        user_inputs['S_smooth_factor'] = 5            \n",
    "\n",
    "    if user_inputs['S_remove_center']:\n",
    "        try:\n",
    "            num = float(user_inputs['S_percentage_removal'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid central percentage removal in Smoothness calculation: {user_inputs['S_percentage_removal']}. Proceeding with a default value (5%)...\", UserWarning)\n",
    "            user_inputs['S_percentage_removal'] = 5.0\n",
    "    \n",
    "        if (user_inputs['S_percentage_removal'] <= 0) | (user_inputs['S_percentage_removal'] >= 100):\n",
    "            warnings.warn(f\"Inconsistent central percentage removal value in Smoothness calculation: {user_inputs['S_percentage_removal']}. Assuming a default value (5%) to continue...\", UserWarning)\n",
    "            user_inputs['S_percentage_removal'] = 5.0            \n",
    "\n",
    "###################################################################################\n",
    "############################ MEGG sanity checks ###################################\n",
    "###################################################################################\n",
    "\n",
    "\n",
    "if user_inputs['measure_indexes']['Moment of Light (M20)']:\n",
    "    try:\n",
    "        num = float(user_inputs['light_fraction'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid light fraction in Moment of Light (M20): {user_inputs['light_fraction']}. Proceeding with a default value (0.2)...\", UserWarning)\n",
    "        user_inputs['light_fraction'] = 0.2\n",
    "\n",
    "    if (user_inputs['light_fraction'] <= 0) :\n",
    "        warnings.warn(f\"Inconsistent light fraction value in Moment of Light (M20) calculation: {user_inputs['light_fraction']}. Assuming a default value (0.2) to continue...\", UserWarning)\n",
    "        user_inputs['light_fraction'] = 0.2            \n",
    "\n",
    "if user_inputs['measure_indexes']['Shannon Entropy']:\n",
    "\n",
    "    if user_inputs['bins_method'] == 'fixed':    \n",
    "        try:\n",
    "            num = float(user_inputs['n_bins'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid Nbins in Shannon Entropy: {user_inputs['n_bins']}. Proceeding with a default value (100)...\", UserWarning)\n",
    "            user_inputs['n_bins'] = 100\n",
    "    \n",
    "        if (user_inputs['n_bins'] <= 0) :\n",
    "            warnings.warn(f\"Inconsistent Nbins value in Shannon Entropy calculation: {user_inputs['n_bins']}. Assuming a default value (100) to continue...\", UserWarning)\n",
    "            user_inputs['n_bins'] = 100            \n",
    "\n",
    "    if user_inputs['remove_entropy_center']:\n",
    "        try:\n",
    "            num = float(user_inputs['remove_entropy_percentage'])\n",
    "        except:\n",
    "            warnings.warn(f\"Invalid central percentage removal in Shannon Entropy calculation: {user_inputs['remove_entropy_percentage']}. Proceeding with a default value (5%)...\", UserWarning)\n",
    "            user_inputs['remove_entropy_percentage'] = 5.0\n",
    "    \n",
    "        if (user_inputs['remove_entropy_percentage'] <= 0) | (user_inputs['remove_entropy_percentage'] >= 100):\n",
    "            warnings.warn(f\"Inconsistent central percentage removal value in Shannon Entropy calculation: {user_inputs['remove_entropy_percentage']}. Assuming a default value (5%) to continue...\", UserWarning)\n",
    "            user_inputs['remove_entropy_percentage'] = 5.0            \n",
    "\n",
    "\n",
    "if user_inputs['measure_indexes']['Gradient Pattern Asymmetry']:\n",
    "\n",
    "    try:\n",
    "        num = float(user_inputs['module_tolerance'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid module tolerance in Gradient Pattern Asymmetry: {user_inputs['module_tolerance']}. Proceeding with a default value (0.05)...\", UserWarning)\n",
    "        user_inputs['module_tolerance'] = 0.05\n",
    "\n",
    "    if (user_inputs['module_tolerance'] <= 0) | (user_inputs['module_tolerance'] >= 1):\n",
    "        warnings.warn(f\"Inconsistent module tolerance value in Gradient Pattern Asymmetry calculation: {user_inputs['module_tolerance']}. Assuming a default value (0.05) to continue...\", UserWarning)\n",
    "        user_inputs['module_tolerance'] = 0.05            \n",
    "    \n",
    "    try:\n",
    "        num = float(user_inputs['phase_tolerance'])\n",
    "    except:\n",
    "        warnings.warn(f\"Invalid phase tolerance in Gradient Pattern Asymmetry: {user_inputs['module_tolerance']}. Proceeding with a default value (10 deg.)...\", UserWarning)\n",
    "        user_inputs['phase_tolerance'] = 10\n",
    "\n",
    "    if (user_inputs['module_tolerance'] <= 0) | (user_inputs['module_tolerance'] >= 360):\n",
    "        warnings.warn(f\"Inconsistent phase tolerance value in Gradient Pattern Asymmetry calculation: {user_inputs['module_tolerance']}. Assuming a default value (10 deg.) to continue...\", UserWarning)\n",
    "        user_inputs['module_tolerance'] = 10\n",
    "\n",
    "#### Cutout check\n",
    "if user_inputs['processing_type'] == 'cutout':\n",
    "    if not os.path.isdir(user_inputs['images_folder']):\n",
    "        raise FileNotFoundError(f\"Folder '{user_inputs['images_folder']}' does not exist.\")\n",
    "\n",
    "    else:\n",
    "        image_array = get_files_with_format(user_inputs['images_folder'], user_inputs['image_format'])\n",
    "        if len(image_array) == 0:\n",
    "            raise FileNotFoundError(f\"{user_inputs['image_format']} files not found in {user_inputs['images_folder']}\")\n",
    "\n",
    "        else:\n",
    "            print(f\"Preparing to process {len(image_array)} {user_inputs['image_format']} images found in {user_inputs['images_folder']} using {user_inputs['n_cores']} cores...\")\n",
    "    x_image = [None] * len(image_array)  # Dummy values for 'cutout'\n",
    "    y_image = [None] * len(image_array)  # Dummy values for 'cutout'\n",
    "  \n",
    "\n",
    "#### Field check\n",
    "if user_inputs['processing_type'] == 'field':\n",
    "    if not os.path.isfile(user_inputs['field_image']):\n",
    "        raise FileNotFoundError(f\"Field image '{user_inputs['images_folder']}' not found.\")\n",
    "\n",
    "    else:\n",
    "        field_file = fits.open(user_inputs['field_image'])\n",
    "        field_header = field_file[1].header\n",
    "        field_data = field_file[1].data\n",
    "        shared_field = shared_memory.SharedMemory(create=True, size=field_data.nbytes)\n",
    "\n",
    "        if user_inputs['initial_cutout_size']<=0:\n",
    "            warnings.warn(f\"Invalid initial cutout size: {user_inputs['initial_cutout_size']}. Proceeding with a default value (100)\", UserWarning)\n",
    "            user_inputs['initial_cutout_size'] = 100\n",
    "\n",
    "        else: \n",
    "            try:\n",
    "                num = float(user_inputs['initial_cutout_size'])\n",
    "                if not num.is_integer():\n",
    "                    warnings.warn(f\"Initial cutout size is not an integer: {num}. Rounding size to {round(num)} to proceed...\", UserWarning)\n",
    "                    user_inputs['initial_cutout_size'] = round(num)\n",
    "            except:\n",
    "                warnings.warn(f\"Invalid initial cutout size format: {num}. Proceeding with a default value (100)...\", UserWarning)\n",
    "                user_inputs['initial_cutout_size'] = 100\n",
    "                \n",
    "       \n",
    "            \n",
    "        if user_inputs['final_cutout_scale']<0:\n",
    "            warnings.warn(f\"Invalid final cutout scale: {user_inputs['final_cutout_scale']}. Proceeding with a default value (10Rp)\", UserWarning)\n",
    "            user_inputs['final_cutout_scale'] = 10\n",
    "            user_inputs['cutout_scale_radius'] = \"Rp\"\n",
    "        else: \n",
    "            try:\n",
    "                num = float(user_inputs['final_cutout_scale'])\n",
    "            except:\n",
    "                warnings.warn(f\"Invalid final cutout size format: {num}. Proceeding with a default value (10Rp)...\", UserWarning)\n",
    "                user_inputs['final_cutout_scale'] = 10\n",
    "                user_inputs['cutout_scale_radius'] = \"Rp\"\n",
    "\n",
    "        if (user_inputs['preprocessing_steps']['Subtract Background']) & (user_inputs['bkg_method'] == 'load'):\n",
    "            if not os.path.isfile(user_inputs['bkg_file']):\n",
    "                raise FileNotFoundError(f\"Background image '{user_inputs['bkg_file']}' not found.\")\n",
    "\n",
    "            elif (user_inputs['field_image'] == user_inputs['bkg_file']):\n",
    "                bkg_field_image = field_file[user_inputs['bkg_hdu']].data\n",
    "            \n",
    "            else: \n",
    "                bkg_file = fits.open(user_inputs['bkg_file'])\n",
    "                bkg_field_image = field_file[user_inputs['bkg_hdu']].data\n",
    "                shared_bkg_field = shared_memory.SharedMemory(create=True, size=bkg_field_image.nbytes)\n",
    "                bkg_file.close()\n",
    "            field_file.close()\n",
    "\n",
    "        \n",
    "        if not os.path.isfile(user_inputs['auxiliary_file']):\n",
    "            raise FileNotFoundError(f\"Auxialiary catalog '{user_inputs['auxiliary_file']}' not found.\")    \n",
    "        \n",
    "        else:\n",
    "            df = pd.read_csv(user_inputs['auxiliary_file'])\n",
    "            l1 = len(df)\n",
    "            if not user_inputs['ra_x'] in df.columns:\n",
    "                raise KeyError(f\"Column '{user_inputs['ra_x']}' not found in the provided CSV file.\")\n",
    "            if not user_inputs['dec_y'] in df.columns:\n",
    "                raise KeyError(f\"Column '{user_inputs['dec_y']}' not found in the provided CSV file.\")\n",
    "\n",
    "            if user_inputs['filter_condition'] != \"\":\n",
    "                \n",
    "                condition_columns = set(re.findall(r\"[a-zA-Z_][a-zA-Z_0-9]*\", user_inputs['filter_condition']))\n",
    "                missing_columns = condition_columns - set(df.columns)\n",
    "                if missing_columns:\n",
    "                    raise KeyError(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "                else:\n",
    "                    df = df.query(user_inputs['filter_condition']).reset_index(drop = True)            \n",
    "                print(f\"Preparing to process the {user_inputs['field_image']} field using {user_inputs['n_cores']} cores... {l1} objects defined from {user_inputs['auxiliary_file']}... {len(df)} remain after applying the {user_inputs['filter_condition']} condition...\")\n",
    "\n",
    "            else:\n",
    "                print(f\"Preparing to process the {user_inputs['field_image']} field using {user_inputs['n_cores']} cores... {l1} Objects defined from {user_inputs['auxiliary_file']}...\")                \n",
    "            if user_inputs['coord_type'] == 'ra/dec':\n",
    "                wcs = WCS(field_header)\n",
    "                ra = df[user_inputs['ra_x']]\n",
    "                dec = df[user_inputs['dec_y']]\n",
    "                coord = SkyCoord(ra, dec, unit=\"deg\", frame=\"icrs\")\n",
    "                x_image, y_image = wcs.world_to_pixel(coord)\n",
    "\n",
    "            if user_inputs['coord_type'] == 'x/y':\n",
    "                x_image, y_image = df[user_inputs['ra_x']].to_numpy(), df[user_inputs['dec_y']].to_numpy() \n",
    "\n",
    "if not user_inputs['preprocessing_steps']['Light Profile Analysis']:\n",
    "    if ((user_inputs['measure_indexes']['Asymmetry']) & (user_inputs['A_remove_center'])) | (user_inputs['measure_indexes']['Smoothness']): \n",
    "        warnings.warn(f\"Inconsistent metrics options with pre-processing steps . Scale radii are only calculated when Light Profile Analysis is enabled. Turning on Light Profile Analysis with default values to proceed...\")\n",
    "            \n",
    "### Pre-processing check\n",
    "if not user_inputs['preprocessing_steps']['Detect']:\n",
    "    if (user_inputs['preprocessing_steps']['Cleaning']) or (user_inputs['preprocessing_steps']['Light Profile Analysis']) or  (user_inputs['preprocessing_steps']['Segmentation']) or (user_inputs['preprocessing_steps']['Flagging']):\n",
    "        warnings.warn(f\"Inconsistent pre-processing steps selection. 'Cleaning', 'Flagging', 'Light Profile Analysis', and 'Segmentation' depend on Object detection. Using default detection options to proceed...\")\n",
    "        user_inputs['preprocessing_steps']['Detect'] = True\n",
    "\n",
    "\n",
    "###################################################################################\n",
    "################## Output tab sanity checkcs ######################################\n",
    "###################################################################################\n",
    "if not os.path.isdir(user_inputs['output_folder']):\n",
    "    warnings.warn(f\"Warning: Folder '{user_inputs['output_folder']}' does not exist. It will be created.\", UserWarning)\n",
    "    os.makedirs(user_inputs['output_folder'])\n",
    "    print(f\"Folder '{user_inputs['output_folder']}' has been created.\")\n",
    "\n",
    "file_path = os.path.join(user_inputs['output_folder'], user_inputs['output_file'])\n",
    "\n",
    "if os.path.exists(file_path):\n",
    "    warnings.warn(f\"Warning: File '{user_inputs['output_file']}' already exists!\", UserWarning)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"File '{user_inputs['output_file']}' already exists. Do you want to overwrite it? (y/n): \").strip().lower()\n",
    "        \n",
    "        if user_input == 'y':\n",
    "            print(f\"Overwriting existing file: {user_inputs['output_file']}\")\n",
    "            final_filename = user_inputs['output_file']\n",
    "            break  # Exit loop and use the original filename\n",
    "            \n",
    "        elif user_input == 'n':\n",
    "            # ✅ Step 3: Find a unique file name\n",
    "            base_name, ext = os.path.splitext(user_inputs['output_file'])\n",
    "            counter = 1\n",
    "            new_filename = f\"{base_name}_{counter}{ext}\"\n",
    "\n",
    "            while os.path.exists(os.path.join(user_inputs['output_folder'], new_filename)):\n",
    "                counter += 1\n",
    "                new_filename = f\"{base_name}_{counter}{ext}\"\n",
    "            \n",
    "            print(f\"File will be saved as: {new_filename} to avoid overwriting.\")\n",
    "            final_filename = new_filename\n",
    "            break  # Exit loop with the new filename\n",
    "        \n",
    "        else:\n",
    "            print(\"Invalid input. Please enter 'y' or 'n'.\")\n",
    "\n",
    "else:\n",
    "    final_filename = user_inputs['output_file']  # No conflict, use the original name\n",
    "\n",
    "output_filepath = os.path.join(user_inputs['output_folder'], final_filename)\n",
    "output_configpath = os.path.join(user_inputs['output_folder'], final_filename.replace('.csv', '.json'))\n",
    "print(f\"Final configuration is saved in {output_configpath}...\")\n",
    "with open(output_configpath, \"w\") as f:\n",
    "    json.dump(user_inputs, f, indent=4)  # indent makes it human-readable\n",
    "print(f\"Step by step progress can be checked in {output_filepath.replace('.csv', '.log')}...\")\n",
    "print(f\"Final output catalog file will be saved as {output_filepath}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a979cfda-7fa7-4185-bdbe-836b62941289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(output_filepath.replace('.csv', '.log'))  # Write logs to a unique file\n",
    "    ]\n",
    ")\n",
    "    \n",
    "# Enable logging for multiprocessing\n",
    "get_logger().setLevel(logging.INFO)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07c5f013-cb3d-4556-a2e2-4b34abf040b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection catalogs will be saved at /home/vitorms/Dropbox/test/Detection Catalogs...\n",
      "Images will be saved... creating folders at /home/vitorms/Dropbox/test...\n"
     ]
    }
   ],
   "source": [
    "if (user_inputs['preprocessing_steps']['Detect']):\n",
    "    folder = os.path.join(user_inputs['output_folder'], 'Detection Catalogs')\n",
    "    print(f\"Detection catalogs will be saved at {folder}...\")\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "\n",
    "if user_inputs['save_images']:\n",
    "    print(f\"Images will be saved... creating folders at {user_inputs['output_folder']}...\")\n",
    "    for image_type in user_inputs['preproc_images']:\n",
    "        if user_inputs['preproc_images'][image_type]:\n",
    "            folder = os.path.join(user_inputs['output_folder'], image_type)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "                \n",
    "    for image_type in user_inputs['output_metrics']:\n",
    "        if user_inputs['output_metrics'][image_type]:\n",
    "            folder = os.path.join(user_inputs['output_folder'], image_type)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "\n",
    "    for image_type in user_inputs['useful_images']:\n",
    "        if user_inputs['useful_images'][image_type]:\n",
    "            folder = os.path.join(user_inputs['output_folder'], image_type)\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0e74ba6-ecc1-4012-a8dc-2bd92dbe5ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parallel Processing Galaxies:  71%|████████▌   | 71/100 [02:12<01:13,  2.55s/it]/home/vitorms/Dropbox/MorphologyExtractor/mexpy/Petrosian_module.py:134: UserWarning: annomaly in eta function, calculating Rp using approximations, results may be not accurate\n",
      "  warnings.warn(\"annomaly in eta function, calculating Rp using approximations, results may be not accurate\", UserWarning)\n",
      "Parallel Processing Galaxies: 100%|███████████| 100/100 [03:06<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Finished processing 10 galaxies in 187.17 seconds\n",
      "⏱️ Estimated time per object: 1.87 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "if user_inputs['processing_type'] == 'cutout':\n",
    "    task_list = [(image_array[i], user_inputs, None, None) for i in range(len(image_array))]\n",
    "\n",
    "# elif user_inputs['processing_type'] == 'field':\n",
    "#     task_list = [(None, user_inputs, x_image[i], y_image[i]) for i in range(len(x_image))]\n",
    "\n",
    "n_tasks = len(task_list)\n",
    "if user_inputs['n_cores'] == 1:\n",
    "    results = []\n",
    "    for i in tqdm(range(n_tasks), desc=\"Serial Galaxy Processing\"):\n",
    "        result = process_galaxy(*task_list[i])\n",
    "        results.append(result)\n",
    "\n",
    "    \n",
    "elif user_inputs['n_cores'] > 1:\n",
    "    with Pool(user_inputs['n_cores']) as pool:\n",
    "        results = list(tqdm(pool.imap_unordered(process_galaxy_wrapper, task_list),\n",
    "                                                total=n_tasks,\n",
    "                                                desc=\"Parallel Processing Galaxies\"))\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(output_filepath, index = False)\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "per_obj = elapsed / n_tasks\n",
    "print(f\"\\n✅ Finished processing 10 galaxies in {elapsed:.2f} seconds\")\n",
    "print(f\"⏱️ Estimated time per object: {per_obj:.2f} seconds\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
